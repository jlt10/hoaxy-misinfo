{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article-based Tweet Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch from Hoaxy API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9yiZsweZn3To",
    "outputId": "424e3230-cdac-4663-c738-07583460d599"
   },
   "outputs": [],
   "source": [
    "# Get network of a tweet\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://api-hoaxy.p.rapidapi.com\"\n",
    "\n",
    "headers = {\n",
    "    'x-rapidapi-key': \"6dda23c3b6msh40fb43640818777p173117jsn2e799b5b84a7\",\n",
    "    'x-rapidapi-host': \"api-hoaxy.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "def fetch_article_tweets(article_id):\n",
    "    querystring = {\"ids\": str([article_id])}\n",
    "    response = requests.request(\"GET\", url+\"/tweets\", headers=headers, params=querystring)\n",
    "    return json.loads(response.text)\n",
    "\n",
    "def fetch_article_network(article_id, node_limit=2000, edge_limit=200000, include_mentions=False):\n",
    "    querystring = {\n",
    "        \"ids\":str([article_id]), # ids must be an array\n",
    "        \"nodes_limit\":str(node_limit), \n",
    "        \"edges_limit\":str(edge_limit), \n",
    "        \"include_user_mentions\": \"true\" if include_mentions else \"false\",\n",
    "    }\n",
    "    response = requests.request(\"GET\", url+\"/network\", headers=headers, params=querystring)\n",
    "    return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article_id = 2147762\n",
    "# raw_tweets = fetch_article_tweets(article_id)[\"tweets\"]\n",
    "# raw_network = fetch_article_network(article_id)[\"edges\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Information\n",
    "\n",
    "Edge directionality represents the flow of information, e.g., from the retweeted to the retweeter account or from the mentioning to the mentioned account.\n",
    "\n",
    "#### Tweet types\n",
    "* `\"retweet\"`\n",
    "    - Tweet is a retweet of a tweet with the article URL.\n",
    "* `\"quote\"`\n",
    "    - Tweet is a quote retweet of a tweet with the article URL.\n",
    "* `\"reply\"`\n",
    "    - Tweet is a reply to a tweet with the article URL.\n",
    "* `\"origin\"`\n",
    "    - Tweet shares the article and mentions the origin site ([example](https://twitter.com/SethRic61410528/status/1321101083029213185))\n",
    "* `None`\n",
    "    - Tweet contains URL but does not fall into any of the other categories. (Not included in network)\n",
    "    - More research needed.\n",
    "\n",
    "### Class Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self, user_id, screen_name):\n",
    "        self.id = user_id\n",
    "        self.screen_name = screen_name\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"User({self.id},{self.screen_name})\"\n",
    "        \n",
    "    def __hash__(self):\n",
    "        return hash(self.id)\n",
    "    \n",
    "    def __eq__(self, obj):\n",
    "        return isinstance(obj, User) and obj.id == self.id\n",
    "\n",
    "class Tweet:\n",
    "    def __init__(self, tweet_dict, from_edge=False):\n",
    "        self.id = tweet_dict[\"tweet_id\"]\n",
    "        self.url = tweet_dict[\"canonical_url\"]\n",
    "        self.created_at = tweet_dict[\"tweet_created_at\"]\n",
    "        if from_edge:\n",
    "            self.is_mention = tweet_dict[\"is_mention\"]\n",
    "            self.type = tweet_dict[\"tweet_type\"]\n",
    "            self.url_id = tweet_dict[\"url_id\"]\n",
    "            user_key = (\"from\" if self.type == \"origin\" else \"to\") + \"_user_id\"\n",
    "            self.user_id = tweet_dict[user_key]\n",
    "        else:\n",
    "            self.is_mention = None\n",
    "            self.type = None\n",
    "            self.url_id = None\n",
    "            self.user_id = None\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"Tweet(id={self.id},created={self.created_at})\"\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.id)\n",
    "    \n",
    "    def __eq__(self, obj):\n",
    "        return isinstance(obj, Tweet) and obj.id == self.id\n",
    "\n",
    "class Edge:\n",
    "    def __init__(self, edge_dict):\n",
    "        self.url = edge_dict[\"canonical_url\"]\n",
    "        self.article_id = edge_dict[\"id\"]\n",
    "        self.from_user = User(\n",
    "            edge_dict[\"from_user_id\"], \n",
    "            edge_dict[\"from_user_screen_name\"]\n",
    "        )\n",
    "        self.to_user = User(\n",
    "            edge_dict[\"to_user_id\"], \n",
    "            edge_dict[\"to_user_screen_name\"]\n",
    "        )\n",
    "        self.tweet = Tweet(edge_dict, from_edge=True)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Edge(tweet={self.tweet.id},from={self.from_user.id},to={self.to_user.id})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_data(raw_network, raw_tweets):\n",
    "    # Initialize collections.\n",
    "    users = dict()\n",
    "    network = dict()\n",
    "    tweets = {t[\"tweet_id\"]: Tweet(t) for t in raw_tweets}\n",
    "    # Iterate through the network.\n",
    "    for e in raw_network:\n",
    "        edge = Edge(e)\n",
    "        tweets[edge.tweet.id] = edge.tweet\n",
    "        network[edge.tweet.id] = edge\n",
    "        users[edge.from_user.id] = edge.from_user\n",
    "        users[edge.to_user.id] = edge.to_user\n",
    "    # Return the collections.\n",
    "    return users, network, tweets\n",
    "\n",
    "# users, network, tweets = parse_raw_data(raw_network, raw_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Network Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_data_path = \"../data/networks/\"\n",
    "\n",
    "def save_user_csv_data(article_id, data_path, users):\n",
    "    with open(f\"{data_path}{article_id}_users.csv\", \"w\") as f:\n",
    "        f.write(\"id,screen_name\\n\")\n",
    "        for u in users.values():\n",
    "            f.write(f\"{u.id},{u.screen_name}\\n\")\n",
    "\n",
    "def save_tweet_csv_data(article_id, data_path, tweets):\n",
    "    with open(f\"{data_path}{article_id}_tweets.csv\", \"w\") as f:\n",
    "        f.write(\"id,url_id,user_id,created_at,type,is_mention\\n\")\n",
    "        for t in tweets.values():\n",
    "            f.write(f\"{t.id},{t.url_id},{t.user_id},{t.created_at},{t.type},{t.is_mention}\\n\")\n",
    "            \n",
    "def save_network_csv_data(article_id, data_path, network):\n",
    "    with open(f\"{data_path}{article_id}_edges.csv\", \"w\") as f:\n",
    "        f.write(\"tweet_id,url,from_user_id,to_user_id\\n\")\n",
    "        for e in network.values():\n",
    "            f.write(f\"{e.tweet.id},{e.url},{e.from_user.id},{e.to_user.id}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_article_hoaxy_data(article_id, data_path):\n",
    "    # Fetch tweets and network from API\n",
    "    raw_tweets = fetch_article_tweets(article_id)[\"tweets\"]\n",
    "    raw_network = fetch_article_network(article_id)[\"edges\"]\n",
    "    # Parse raw data into users, networks, and tweets\n",
    "    users, network, tweets = parse_raw_data(raw_network, raw_tweets)\n",
    "    # Save all the data\n",
    "    save_user_csv_data(article_id, data_path, users)\n",
    "    save_tweet_csv_data(article_id, data_path, tweets)\n",
    "    save_network_csv_data(article_id, data_path, network)\n",
    "\n",
    "save_article_hoaxy_data(2147762, network_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TweetNetwork.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
