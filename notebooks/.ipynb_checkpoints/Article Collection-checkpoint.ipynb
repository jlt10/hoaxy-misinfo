{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect All Article Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the articles\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://api-hoaxy.p.rapidapi.com/articles\"\n",
    "\n",
    "headers = {\n",
    "    'x-rapidapi-host': \"api-hoaxy.p.rapidapi.com\",\n",
    "    'x-rapidapi-key': \"6dda23c3b6msh40fb43640818777p173117jsn2e799b5b84a7\"\n",
    "    }\n",
    "\n",
    "vbm_query = \"(mailin or ballot or votebymail)\"\n",
    "\n",
    "def fetch_articles(querystring):\n",
    "  query = {\"sort_by\":\"relevant\",\"use_lucene_syntax\":\"true\",\"query\":querystring}\n",
    "  response = requests.request(\"GET\", url, headers=headers, params=query)\n",
    "  return json.loads(response.text)\n",
    "\n",
    "# print(fetch_articles(vbm_query)['articles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def collect_artcicles_over_time(base_query, start_yr=2016, end_yr=2020, step=14):\n",
    "  articles = []\n",
    "  start = date(start_yr, 1, 1)\n",
    "  while start.year < end_yr + 1:\n",
    "    end = start + relativedelta(days=step)\n",
    "    # Query for mail in voting articles published within this time period.\n",
    "    querystring = base_query + f\" AND date_published:[{start.isoformat()} TO {end.isoformat()}]\"\n",
    "    res = fetch_articles(querystring)\n",
    "    if 'articles' in res.keys():\n",
    "      articles.extend(res['articles'])\n",
    "    # Update the start date so there's no overlap.\n",
    "    start = end + relativedelta(days=+1)\n",
    "  return articles\n",
    "\n",
    "articles_18 = collect_artcicles_over_time(vbm_query, start_yr=2018, end_yr=2018)\n",
    "articles_20 = collect_artcicles_over_time(vbm_query, start_yr=2020, end_yr=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num articles 4403\n",
      "num unique ids 4403\n"
     ]
    }
   ],
   "source": [
    "articles = [Article(a) for a in articles_18 + articles_20]\n",
    "print(\"num articles\", len(articles))\n",
    "ids = set(map(lambda x: x.id, articles))\n",
    "print(\"num unique ids\", len(set(ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Article Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class Article:\n",
    "    def __init__(self, article_dict):\n",
    "        self.id = article_dict['id']\n",
    "        self.title = article_dict['title']\n",
    "        self.date_published = article_dict['date_published']\n",
    "        self.url = article_dict['canonical_url']\n",
    "        self.domain = article_dict['domain']\n",
    "        self.num_tweets = article_dict['number_of_tweets']\n",
    "        self.score = article_dict['score']\n",
    "        self.site_type = article_dict['site_type']\n",
    "    \n",
    "    def write_to_csv(csv):\n",
    "        csv.write(f\"{self.id},{self.title},{self.date_published},{self.url},{self.domain},{self.num_tweets},{self.score},{self.site_type},\\n\")\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Article({self.id}, {self.title}, {self.url})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'canonical_url': 'http://www.politicususa.com/2018/01/12/trump-13.html/amp', 'date_published': '2018-01-12T00:00:00.000Z', 'domain': 'politicususa.com', 'id': 817272, 'number_of_tweets': 377, 'score': 8.93126297, 'site_type': 'claim', 'title': 'Trump’s Porn Star Payoff Is The Final Nail In The Republican Party’s Coffin'}\n",
      "Article(817272, Trump’s Porn Star Payoff Is The Final Nail In The Republican Party’s Coffin, http://www.politicususa.com/2018/01/12/trump-13.html/amp)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data\"\n",
    "\n",
    "with open(data_path + \"/all_articles.csv\", \"w\") as f:\n",
    "    for a in articles:\n",
    "        a.write_to_csv(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
